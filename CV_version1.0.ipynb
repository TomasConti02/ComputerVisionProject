{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e301d64-c216-4c11-8419-d503c17f7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Elaborazione Dati e Calcolo Scientifico\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Visualizzazione\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning (TensorFlow/Keras)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from classification_models.tfkeras import Classifiers\n",
    "\n",
    "# Machine Learning Utility (Scikit-learn)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Configurazione ambiente\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77131824-4620-4ab4-95ae-84126f3eedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/marcusklasson/GroceryStoreDataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2751cdc-4922-4083-b741-351a5f671431",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install image-classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a1982-503e-4ed2-9f56-ab3dbd55bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated to match your directory listing\n",
    "ROOT_DIR = \"/content/GroceryStoreDataset/dataset/\"\n",
    "classes_df = pd.read_csv(os.path.join(ROOT_DIR, \"classes.csv\"))\n",
    "print(f\"Shape: {classes_df.shape}\")\n",
    "print(f\"Unique Classes: {classes_df['Class ID (int)'].unique()}\")\n",
    "classes_df.head()\n",
    "\n",
    "def process_dataframe_fixed(df, root_dir):\n",
    "    df['path'] = df['path'].apply(lambda x: os.path.join(root_dir, x))\n",
    "    # Convertiamo ogni singola cella in stringa\n",
    "    df['fine_label'] = df['fine_label'].astype(str)\n",
    "    return df\n",
    "    \n",
    "# Ricarica i dati per pulire errori precedenti\n",
    "train_df = pd.read_csv(os.path.join(ROOT_DIR, \"train.txt\"), header=None, sep=\",\", names=['path', 'fine_label', 'coarse_label'])\n",
    "val_df   = pd.read_csv(os.path.join(ROOT_DIR, \"val.txt\"), header=None, sep=\",\", names=['path', 'fine_label', 'coarse_label'])\n",
    "test_df  = pd.read_csv(os.path.join(ROOT_DIR, \"test.txt\"), header=None, sep=\",\", names=['path', 'fine_label', 'coarse_label'])\n",
    "train_df = process_dataframe_fixed(train_df, ROOT_DIR)\n",
    "val_df = process_dataframe_fixed(val_df, ROOT_DIR)\n",
    "test_df = process_dataframe_fixed(test_df, ROOT_DIR)\n",
    "print(f\"Classi uniche in Train: {train_df['fine_label'].nunique()}\")\n",
    "print(f\"Classi uniche in Val:   {val_df['fine_label'].nunique()}\")\n",
    "print(f\"Classi uniche in Test:  {test_df['fine_label'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da7f5b-5e65-42cd-a816-fba7b40e8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([train_df, val_df], ignore_index=True)\n",
    "lista_classi = sorted(df_combined['fine_label'].unique().tolist())\n",
    "NUM_CLASSES = len(lista_classi)\n",
    "\n",
    "train_df_new, val_df_new = train_test_split(\n",
    "    df_combined,\n",
    "    test_size=0.20,\n",
    "    stratify=df_combined['fine_label'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d479af7-aac4-436e-bf41-daa3becd4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_RAW_H, IMG_RAW_W = 256, 256\n",
    "IMG_CROP_H, IMG_CROP_W = 224, 224\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 60\n",
    "\n",
    "# ImageDataGenerator per il caricamento (solo rescaling)\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_new,\n",
    "    x_col='path',\n",
    "    y_col='fine_label',\n",
    "    target_size=(IMG_RAW_H, IMG_RAW_W),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=lista_classi,\n",
    "    shuffle=True\n",
    ")\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df_new,\n",
    "    x_col='path',\n",
    "    y_col='fine_label',\n",
    "    target_size=(IMG_RAW_H, IMG_RAW_W),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=lista_classi,\n",
    "    shuffle=False\n",
    ")\n",
    "# Calcolo pesi delle classi\n",
    "train_labels = train_generator.classes\n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "dict_weights = dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b0613-d4fa-4145-8a52-2fc17bf8c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_final_model(input_shape_raw, crop_height, crop_width, num_classes):\n",
    "    # Definizione esplicita dell'input\n",
    "    inputs = layers.Input(shape=input_shape_raw)\n",
    "\n",
    "    # DATA AUGMENTATION (Attiva solo in fase di training)\n",
    "    x = layers.RandomCrop(crop_height, crop_width)(inputs)\n",
    "    #x = layers.RandomFlip(\"horizontal\")(x)\n",
    "    #x = layers.RandomRotation(0.2)(x)\n",
    "    #x = layers.RandomContrast(0.1)(x)\n",
    "    x = layers.RandomFlip(\"horizontal\")(x)\n",
    "    x = layers.RandomRotation(0.2)(x)\n",
    "    x = layers.RandomContrast(0.1)(x)\n",
    "    x = layers.RandomZoom(0.1)(x)\n",
    "    x = layers.RandomTranslation(0.1,0.1)(x)\n",
    "    \n",
    "    # Blocchi Convoluzionali (Simil-VGG ma con BatchNormalization e Dropout)\n",
    "    # Blocco 1\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Blocco 2\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Blocco 3\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Blocco 4\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Classifier\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.02))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e717b-4d13-4af6-acce-c95a35e873f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_final_model(\n",
    "    input_shape_raw=(IMG_RAW_H, IMG_RAW_W, CHANNELS),\n",
    "    crop_height=IMG_CROP_H,\n",
    "    crop_width=IMG_CROP_W,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0004),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Callback (EarlyStopping e Learning Rate Decay)\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=dict_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf66c17-f19a-450e-9ecf-b80c9a62e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Grafico Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Grafico Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_final_evaluation(model, generator, title=\"Validation Set\"):\n",
    "    print(f\"\\n--- Valutazione su: {title} ---\")\n",
    "\n",
    "    # 1. Reset del generatore (fondamentale per mantenere l'ordine)\n",
    "    generator.reset()\n",
    "\n",
    "    # 2. Ottenere le predizioni\n",
    "    y_pred_probs = model.predict(generator)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = generator.classes\n",
    "\n",
    "    # 3. Calcolo e visualizzazione Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    sns.heatmap(cm, annot=False, cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix ({title})')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Classification Report\n",
    "    class_labels = list(generator.class_indices.keys())\n",
    "    print(f\"\\n--- Classification Report ({title}) ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "plot_final_evaluation(model, val_generator, title=\"Validation Set\")\n",
    "\n",
    "plot_final_evaluation(model, test_generator, title=\"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ec784-d517-4734-9c5b-82232dae452b",
   "metadata": {},
   "source": [
    "REST-NET tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c8eb63-f200-4bc8-b5f3-9a4292b01b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "\n",
    "# =========================\n",
    "# 2. GENERATORI DATI\n",
    "# =========================\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_new,\n",
    "    x_col='path',\n",
    "    y_col='fine_label',\n",
    "    target_size=(IMG_RAW_H, IMG_RAW_W),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=lista_classi,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df_new,\n",
    "    x_col='path',\n",
    "    y_col='fine_label',\n",
    "    target_size=(IMG_RAW_H, IMG_RAW_W),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=lista_classi,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3. CLASS WEIGHTS\n",
    "# =========================\n",
    "train_labels = train_generator.classes\n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "dict_weights = dict(enumerate(weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf13b48-8861-4924-8ae5-d721a95fdde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_resnet18_advanced(num_classes, learning_rate, fine_tune=False):\n",
    "\n",
    "    inputs = layers.Input(shape=(IMG_RAW_H, IMG_RAW_W, 3), name=\"input_image\")\n",
    "\n",
    "    # ---- Augmentation interna ----\n",
    "    x = layers.RandomCrop(IMG_CROP_H, IMG_CROP_W)(inputs)\n",
    "    x = layers.RandomFlip(\"horizontal\")(x)\n",
    "    x = layers.RandomRotation(0.2)(x)\n",
    "    x = layers.RandomContrast(0.1)(x)\n",
    "    x = layers.RandomZoom(0.1)(x)\n",
    "    x = layers.RandomTranslation(0.1,0.1)(x)\n",
    "\n",
    "    # ---- Base Model ----\n",
    "    base_model = ResNet18(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=x\n",
    "    )\n",
    "    base_model.trainable = fine_tune\n",
    "\n",
    "    if fine_tune:\n",
    "        for layer in base_model.layers:\n",
    "            if isinstance(layer, layers.BatchNormalization):\n",
    "                layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "\n",
    "    # ---- Classification Head ----\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.02))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a08a06-224d-4999-b379-a2b25d02b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 4. COSTRUZIONE MODELLO\n",
    "# =========================\n",
    "# =========================\n",
    "# 5. CALLBACKS\n",
    "# =========================\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 6. TRAINING WARM-UP\n",
    "# =========================\n",
    "tf.keras.backend.clear_session()\n",
    "print(\"\\n>>> FASE 1: Warm-up (Base Congelata)\")\n",
    "model = build_resnet18_advanced(NUM_CLASSES, learning_rate=1e-3, fine_tune=False)\n",
    "\n",
    "history_warmup = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=dict_weights,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 7. FINE-TUNING\n",
    "# =========================\n",
    "print(\"\\n>>> FASE 2: Fine-tuning (Base Sbloccata)\")\n",
    "weights_warmup = model.get_weights()\n",
    "model = build_resnet18_advanced(NUM_CLASSES, learning_rate=1e-5, fine_tune=True)\n",
    "model.set_weights(weights_warmup)\n",
    "\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=dict_weights,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0916be-b0bf-4c60-bf1f-e09b73c45a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 8. VALIDAZIONE COMPLETA\n",
    "# =========================\n",
    "def plot_history(history, title=\"Training History\"):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title(title + \" - Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(title + \" - Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_warmup, title=\"Warm-up\")\n",
    "plot_history(history_finetune, title=\"Fine-tuning\")\n",
    "\n",
    "# Classification report + confusion matrix\n",
    "val_generator.reset()\n",
    "y_pred = model.predict(val_generator, verbose=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=lista_classi))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Validation Set\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# 9. TEST GENERATOR & EVALUATION\n",
    "# =========================\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='path',\n",
    "    y_col='fine_label',\n",
    "    target_size=(IMG_RAW_H, IMG_RAW_W),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=lista_classi,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
